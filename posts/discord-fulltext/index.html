<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>&lt;Discord 如何 Full-text Index 數十億的訊息> - Tachunn Publication</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Index 前言 需求 解決方案 Question 1：我該用外部的 SaaS 去解決這個問題嗎？ Question 2：有 Open-source 的方案可以用嗎？ 我們該”全面”相信 Elasticsearch 嗎？ 元件的細節 高層次分析 Insert 元件 Shard Manage 元件 Indexing & Mapping the Data 實際上 Coding 的實作 實際在 Production 的過程 初始化實驗 研究的精神 更新的煩惱 The Future Example：Unhealthy Cluster (ran out of heap) Example：Healthy Cluster 結論 感想 前言 這篇部落格會翻譯和參考 <How discord indexes billions of messages> 這篇文章的內容做整理和翻譯。
這篇算是 <Discord 如何處理數十億的訊息> 的下集，當有了最核心的訊息讀寫系統。下一個很重要的 feature 就是 Full-text Search。
舉例來說，User 突然想到以前和同伴討論的某個議題，不可能慢慢滑去找，而是要用像是 Search Engine 這樣的功能，這篇文章就是在介紹 Discord 如何做到這種功能。"><meta property="og:image" content><meta property="og:title" content="<Discord 如何 Full-text Index 數十億的訊息>"><meta property="og:description" content="Index 前言 需求 解決方案 Question 1：我該用外部的 SaaS 去解決這個問題嗎？ Question 2：有 Open-source 的方案可以用嗎？ 我們該”全面”相信 Elasticsearch 嗎？ 元件的細節 高層次分析 Insert 元件 Shard Manage 元件 Indexing & Mapping the Data 實際上 Coding 的實作 實際在 Production 的過程 初始化實驗 研究的精神 更新的煩惱 The Future Example：Unhealthy Cluster (ran out of heap) Example：Healthy Cluster 結論 感想 前言 這篇部落格會翻譯和參考 <How discord indexes billions of messages> 這篇文章的內容做整理和翻譯。
這篇算是 <Discord 如何處理數十億的訊息> 的下集，當有了最核心的訊息讀寫系統。下一個很重要的 feature 就是 Full-text Search。
舉例來說，User 突然想到以前和同伴討論的某個議題，不可能慢慢滑去找，而是要用像是 Search Engine 這樣的功能，這篇文章就是在介紹 Discord 如何做到這種功能。"><meta property="og:type" content="article"><meta property="og:url" content="https://tachunwu.github.io/posts/discord-fulltext/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-30T18:02:17+08:00"><meta property="article:modified_time" content="2023-01-30T18:02:17+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="<Discord 如何 Full-text Index 數十億的訊息>"><meta name=twitter:description content="Index 前言 需求 解決方案 Question 1：我該用外部的 SaaS 去解決這個問題嗎？ Question 2：有 Open-source 的方案可以用嗎？ 我們該”全面”相信 Elasticsearch 嗎？ 元件的細節 高層次分析 Insert 元件 Shard Manage 元件 Indexing & Mapping the Data 實際上 Coding 的實作 實際在 Production 的過程 初始化實驗 研究的精神 更新的煩惱 The Future Example：Unhealthy Cluster (ran out of heap) Example：Healthy Cluster 結論 感想 前言 這篇部落格會翻譯和參考 <How discord indexes billions of messages> 這篇文章的內容做整理和翻譯。
這篇算是 <Discord 如何處理數十億的訊息> 的下集，當有了最核心的訊息讀寫系統。下一個很重要的 feature 就是 Full-text Search。
舉例來說，User 突然想到以前和同伴討論的某個議題，不可能慢慢滑去找，而是要用像是 Search Engine 這樣的功能，這篇文章就是在介紹 Discord 如何做到這種功能。"><script src=https://tachunwu.github.io/js/feather.min.js></script>
<link href=https://tachunwu.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://tachunwu.github.io/css/main.ac08a4c9714baa859217f92f051deb58df2938ec352b506df655005dcaf98cc0.css></head><body><div class=content><header><script async src="https://www.googletagmanager.com/gtag/js?id=G-2LYZQ778V0"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2LYZQ778V0")</script><div class=main><a href=https://tachunwu.github.io/>Tachunn Publication</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>&lt;Discord 如何 Full-text Index 數十億的訊息></h1><div class=meta>Posted on Jan 30, 2023</div></div><section class=body><p><img src=/images/discord-fulltext_head.png alt><div><h2>Index</h2><nav id=TableOfContents><ol><li><a href=#前言><strong>前言</strong></a></li><li><a href=#需求><strong>需求</strong></a></li><li><a href=#解決方案><strong>解決方案</strong></a><ol><li><a href=#question-1我該用外部的-saas-去解決這個問題嗎><strong>Question 1：我該用外部的 SaaS 去解決這個問題嗎？</strong></a></li><li><a href=#question-2有-open-source-的方案可以用嗎><strong>Question 2：有 Open-source 的方案可以用嗎？</strong></a></li></ol></li><li><a href=#我們該全面相信-elasticsearch-嗎><strong>我們該”全面”相信 Elasticsearch 嗎？</strong></a></li><li><a href=#元件的細節><strong>元件的細節</strong></a><ol><li><a href=#高層次分析><strong>高層次分析</strong></a></li><li><a href=#insert-元件><strong>Insert 元件</strong></a></li><li><a href=#shard-manage-元件><strong>Shard Manage 元件</strong></a></li></ol></li><li><a href=#indexing--mapping-the-data><strong>Indexing & Mapping the Data</strong></a></li><li><a href=#實際上-coding-的實作><strong>實際上 Coding 的實作</strong></a></li><li><a href=#實際在-production-的過程><strong>實際在 Production 的過程</strong></a><ol><li><a href=#初始化實驗><strong>初始化實驗</strong></a></li><li><a href=#研究的精神><strong>研究的精神</strong></a></li><li><a href=#更新的煩惱><strong>更新的煩惱</strong></a></li></ol></li><li><a href=#the-future><strong>The Future</strong></a><ol><li><a href=#exampleunhealthy-cluster-ran-out-of-heap>Example：Unhealthy Cluster (ran out of heap)</a></li><li><a href=#examplehealthy-cluster>Example：<strong><strong>Healthy Cluster</strong></strong></a></li></ol></li><li><a href=#結論><strong>結論</strong></a></li><li><a href=#感想><strong>感想</strong></a></li></ol></nav></div></p><h1 id=前言><strong>前言</strong></h1><p>這篇部落格會翻譯和參考 &lt;<a href=https://discord.com/blog/how-discord-indexes-billions-of-messages>How discord indexes billions of messages</a>> 這篇文章的內容做整理和翻譯。</p><p>這篇算是 &lt;<a href=https://tachunwu.github.io/posts/discord-cassandra/>Discord 如何處理數十億的訊息</a>> 的下集，當有了最核心的訊息讀寫系統。下一個很重要的 feature 就是 <strong>Full-text Search</strong>。</p><p><strong>舉例來說，User 突然想到以前和同伴討論的某個議題，不可能慢慢滑去找，而是要用像是 Search Engine 這樣的功能，這篇文章就是在介紹 Discord 如何做到這種功能。</strong></p><h1 id=需求><strong>需求</strong></h1><p>一開始作者先把需求給羅列清楚：</p><ul><li><strong><a href>Cost Effective</a></strong>：</li></ul><p>對於 Discord 來說，主要的服務還是語音和訊息，<strong>全文搜尋的功能算是附加的功能</strong>，就意味著我們<strong>不應該在這個功能花過多得費用 (至少要比語音和訊息的 Infra 還少！)</strong></p><ul><li><strong><a href>Fast & Intuitive</a></strong>：</li></ul><p>當然加一個新功能需要能讓使用者覺得很順利很好用，這是基本。</p><ul><li><strong><a href>Self-healing</a></strong>：</li></ul><p>由於我們的團隊還沒有 DevOps 團隊，我們希望可以 Self-healing</p><ul><li><strong><a href>Linearly Scalable</a></strong>：</li></ul><p>畢竟 Discord 是超大流量的公司，我們當然希望能夠<strong>單純增加 Node 就能增加 throughput</strong>。</p><ul><li><strong><a href>Lazily Indexed</a></strong>：</li></ul><p>由於並不是每一個 User 都會使用 Index，<strong>只要 User 不使用我們就不該做這件事情</strong>，另外如果 Index 失敗了，我們要有辦法重新 Index。</p><h1 id=解決方案><strong>解決方案</strong></h1><p>當我們仔細思量上面統整的需求，我們總和出了兩個主要問題。</p><h2 id=question-1我該用外部的-saas-去解決這個問題嗎><strong>Question 1：我該用外部的 SaaS 去解決這個問題嗎？</strong></h2><p>這題的答案絕對是不行！在 Discord 這個 Scale 我們參考了一些外部的廠商，會發現預算一定會爆炸…。再來，我們對於隱私有很大的考量，如果把資料運出去我們的 Data Center 誰知道那些廠商會不會保護好我們的資料？</p><h2 id=question-2有-open-source-的方案可以用嗎><strong>Question 2：有 Open-source 的方案可以用嗎？</strong></h2><p>有的！我們內部討論之後，發現有 Elasticsearch 和 Solr 可以選擇，我們發現 Elasticsearch 有以下優勢。</p><ul><li><a href>Solr 本身需要搭配 ZooKeeper，我們內部是用 etcd，我們不想花精力去維護額外的基礎設施</a>。還有 Elasticsearch’s Zen 本身有內建的服務發現，這方面比 Solr 有更多優勢。</li><li>Elasticsearch 支援 <a href>automatic shard rebalancing (分片自動平衡)</a>，當我們增加新的 Node 可以滿足 Linearly Scalable 這個需求。</li><li>Elasticsearch 本身有內建自己的查詢語言 (structured query DSL)，不需要像 Solr 寫第三方的查詢字串。</li><li>我們的工程師對 Elasticsearch 比較有經驗… XD</li></ul><p><em><a href>註記1</a>：這篇文章是 2017 年寫的，那時的 Full-text 基礎設施的確不多，但是現在已經有很新的解決方案，例如：Meilisearch、Zinc、Typesense，甚至如果你流量沒有像 Discord 那摩暴力，Postgres 本身其實也有 Full-text Search。</em></p><p><em><a href>註記2</a>：automatic shard rebalancing，這個詞的意思是指當資料量過大時必須要分散在不同的 Node這是 shard 的意思。當增加新的 Node 裡面還沒有資料較需要把部分資料做搬移，就是 rebalancing。而 automatic 就是照整個過程是系統自動完成的 (Actually 這個 feature 是很難做的如果又要 online 做)。</em></p><h1 id=我們該全面相信-elasticsearch-嗎><strong>我們該”全面”相信 Elasticsearch 嗎？</strong></h1><p>經由我們的分析 Elasticsearch 雖然所有我們想要的 feature 都有提供，但是我們並沒有管理大型 Elasticsearch Cluster 的經驗，我們目前只有拿來做 log 的用途，All-in實在是會怕。</p><p>所以我們選擇一個折衷的方案，<strong>我們在 Application Layer 做 sharding 和 routing</strong>，<strong>我們維護很多小小的 Elasticsearch Cluster，就算故障了，也只有那個 shard 的 user 會被影響。就算更誇張一點，整個小 Cluster 都死了，下次再 lazily re-index 就好。</strong></p><h1 id=元件的細節><strong>元件的細節</strong></h1><h2 id=高層次分析><strong>高層次分析</strong></h2><p><strong>Elasticsearch 語意上是以 bulk 的方式 indexed</strong>，也就意味著我們沒辦法 Real-time 的更新。我們<strong>採取一個 Queue 的方式，再用 worker batch 寫入</strong>。至於這種延遲之所以可以忍受，是<strong>因為多半用到 Full-text 的人都是搜尋歷史紀錄，沒有必要做到 Real-time</strong>，以下我們開始介紹有什麼元件。</p><h2 id=insert-元件><strong>Insert 元件</strong></h2><ul><li><strong><a href>Message Queue</a></strong>：可以先把 Messages buffer 起來。</li><li><strong><a href>Index Workers</a></strong>：專門把 Messages 從 Message Queue 送入 Elasticsearch。</li><li><strong><a href>Historical Index Workers</a></strong>：負責把 Messages 歷史紀錄 送入 Elasticsearch。</li></ul><h2 id=shard-manage-元件><strong>Shard Manage 元件</strong></h2><p>由於剛剛我上面有說 <strong>Discord 自行管理很多 Elastic Search Cluster</strong>，<strong>我們把 (Elasticsearch cluster, Discord server Index) 作為 shard 的管理</strong>，就是 Application 需要把 cluster + index 轉換成 shard，又可以拆分成以下兩層：</p><ul><li><strong><a href>Persistent Shard Mapping</a></strong>：</li></ul><p>我們把這種 <strong>Mapping 放在 Cassandra (我們的主要資料庫)</strong></p><ul><li><strong><a href>Shard Mapping Cache</a></strong>：</li></ul><p>如果每次 Discord server 要去找自己的 Full-text Index shard，都要進去 Cassandra 查會很浪費時間，<strong>所以用 Redis Cache 起來，並且用 mget 來得到結果</strong>。</p><p>當 Discord server 第一次請求 Index 時我們需要決定要用哪一個 Shard，由於邏輯是寫在 Application 我們用 Redis 做了一個 <strong>load aware shard allocator</strong>。</p><ul><li><strong><a href>Shard Allocator</a></strong>：</li></ul><p><strong>我們用 Redis 的 sorted set 來實作，我們幫每一個 Shard 排序一個分數，分數意味 load，得分最低的就會是下次被分配的 shard。每一次分配都會更新分數，當 shard 的分數變高，未來被分配到的機率就會越低。</strong></p><p>雖然上面的設計已經很完整了，<strong>但是要能夠動起來需要讓服務被發現，我們需要協調 Application 和 Infra</strong>。</p><ul><li><strong><a href>etcd</a></strong>：</li></ul><p>這個工作就由 <strong>etcd 負責 service discovery</strong>，etcd 可以管理的很好，我們不用去手刻Elasticsearch topologies 管理層。</p><ul><li><strong><a href>Search API</a></strong>：</li></ul><p>最外層還是要包成 API，主要只是驗證有沒有權限去察看某些 Index</p><p><em><a href>註記</a>：etcd 可是 kubernetes 的核心，基本上屬於超級強的實戰系統！Respect！</em></p><h1 id=indexing--mapping-the-data><strong>Indexing & Mapping the Data</strong></h1><p>在最抽象的層次，<strong>我們其實就只是一堆 shards 而這些 shards 是 Lucene index</strong> (如果去查一下 wiki，Elasticsearch 就是用 Apache Lucene Java Library 實作的)。如果你想要你可以用 <strong>routing key</strong> 來分配 sharding 的位置。</p><p>細節上我們還可以設計 replica，<strong>複製多份同樣的 shard 一來可以增加 HA 的特性，二來可以衝高特定熱門 shard 的 throughput。</strong></p><p><strong>雖然我們已經自己在 Application Level 手刻 Sharding，我們壓根沒在用 Elasticsearch shard，但是 replication 和 balancing 在 Elasticsearch 小 cluster 還是蠻好用的，以下就介紹一下我們怎麼設定。</strong></p><ul><li><a href>index 只能有屬於一個 shard</a></li><li><a href>index 應該 replicated 到另外一個 node，primary 掛掉了服務還能繼續</a></li><li><a href>index 60 秒刷新一次，為什麼不是 Real-time 上面有解釋</a></li><li><a href>index 只有一種 document type：message</a></li></ul><p>最後一點特別解釋，我們不存原始的資料，這種意義不大，我們順便把 metadata 啥的全都塞進去，這樣就可以搜到超多東西，以下是我們 index 模板的範例。可以看到，縮有東西都塞…塞進去了，簡單暴力！</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;template&#39;</span>: <span style=color:#e6db74>&#39;m-*&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;settings&#39;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;number_of_shards&#39;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;number_of_replicas&#39;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;index.refresh_interval&#39;</span>: <span style=color:#e6db74>&#39;3600s&#39;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;mappings&#39;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;message&#39;</span>: {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;_source&#39;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;includes&#39;</span>: [
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;id&#39;</span>,
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;channel_id&#39;</span>,
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;guild_id&#39;</span>
</span></span><span style=display:flex><span>                ]
</span></span><span style=display:flex><span>            },
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;properties&#39;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#75715e># This is the message_id, we index by this to allow for greater than/less than queries, so we can search</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># before, on, and after.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;id&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;long&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Lets us search with the &#34;in:#channel-name&#34; modifier.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;channel_id&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;long&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Lets us scope a search to a given server.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;guild_id&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;long&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Lets us search &#34;from:Someone#0001&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;author_id&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;long&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Is the author a user, bot or webhook? Not yet exposed in client.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;author_type&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;byte&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Regular chat message, system message...</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;type&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;short&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Who was mentioned, &#34;mentions:Person#1234&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;mentions&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;long&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Was &#34;@everyone&#34; mentioned (only true if the author had permission to @everyone at the time).</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># This accounts for the case where &#34;@everyone&#34; could be in a message, but it had no effect, </span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># because the user doesn&#39;t have permissions to ping everyone. </span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;mention_everyone&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;boolean&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Array of [message content, embed title, embed author, embed description, ...]</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># for full-text search.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;content&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;text&#39;</span>,
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;fields&#39;</span>: {
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#39;lang_analyzed&#39;</span>: {
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;text&#39;</span>,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;analyzer&#39;</span>: <span style=color:#e6db74>&#39;english&#39;</span>
</span></span><span style=display:flex><span>                        }
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># An array of shorts, specifying what type of media the message has. &#34;has:link|image|video|embed|file&#34;.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;has&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;short&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># An array of normalized hostnames in the message, traverse up to the domain. Not yet exposed in client.</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># &#34;http://foo.bar.com&#34; gets turned into [&#34;foo.bar.com&#34;, &#34;bar.com&#34;]</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;link_hostnames&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;keyword&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Embed providers as returned by oembed, i.e. &#34;Youtube&#34;. Not yet exposed in client.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;embed_providers&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;keyword&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># Embed type as returned by oembed. Not yet exposed in client.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;embed_types&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;keyword&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># File extensions of attachments, i.e. &#34;fileType:mp3&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;attachment_extensions&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;keyword&#39;</span>
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#75715e># The filenames of the attachments. Not yet exposed in client.</span>
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;attachment_filenames&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;type&#39;</span>: <span style=color:#e6db74>&#39;text&#39;</span>,
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;analyzer&#39;</span>: <span style=color:#e6db74>&#39;simple&#39;</span>
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>作者有提到他們<strong>並沒有直接把 messages 存到 Elasticsearch，而是當 inverted index 用</strong>，所以當你搜尋某些關鍵字，<strong>Elasticsearch 不能直接給你資料，而是給你 message, channel 和 server ID，你還是需要拿這些東西去 Cassandra 取回原始資料</strong>。</p><h1 id=實際上-coding-的實作><strong>實際上 Coding 的實作</strong></h1><p>我們決定不用微服務，而是寫一個 library 把 Query 的邏輯包進去。<strong>我們唯一需要的額外服務就是 index worker，也就是上面那個我們把 routing + querying 寫成 library 的使用者</strong>，實際的 API 例子就是下面的 code。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>results <span style=color:#f92672>=</span> router<span style=color:#f92672>.</span>search(SearchQuery(
</span></span><span style=display:flex><span>  guild_id<span style=color:#f92672>=</span><span style=color:#ae81ff>112233445566778899</span>,
</span></span><span style=display:flex><span>  content<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hey jake&#34;</span>,
</span></span><span style=display:flex><span>  channel_ids<span style=color:#f92672>=</span>[<span style=color:#ae81ff>166705234528174080</span>, <span style=color:#ae81ff>228695132507996160</span>]
</span></span><span style=display:flex><span>))
</span></span><span style=display:flex><span>results_with_context <span style=color:#f92672>=</span> gather_results(results, context_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>Queueing 一則訊息用來 indexed/deleted</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># When a message was created or updated:</span>
</span></span><span style=display:flex><span>broker<span style=color:#f92672>.</span>enqueue_message(message)
</span></span><span style=display:flex><span><span style=color:#75715e># When a message was deleted:</span>
</span></span><span style=display:flex><span>broker<span style=color:#f92672>.</span>enqueue_delete(message)
</span></span></code></pre></div><p>Bulk indexing 的 code (被 worker 執行)</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gather_messages</span>(num_to_gather<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>  messages <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>while</span> len(messages) <span style=color:#f92672>&lt;</span> num_to_gather:
</span></span><span style=display:flex><span>    messages<span style=color:#f92672>.</span>append(broker<span style=color:#f92672>.</span>pop_message())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> messages
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>  messages <span style=color:#f92672>=</span> gather_messages()
</span></span><span style=display:flex><span>  router<span style=color:#f92672>.</span>index_messages(messages)
</span></span></code></pre></div><p>接著對於 historical messages，會是以 job 為單位一個一個序列 index，實際上會維護一個 cursor 然後以 500 則 messages 為單位進行處理。處理完成之後會回傳下一個 cursor 直到所有 historical messages 都被 index。</p><p>為了加快大型 server (這裡我想語意指的是我們用的 Discord server，不是他們的 Application Server)，historical indexing 有兩個階段：</p><ol><li><a href>initial</a>：indexes 最近七天的訊息，馬上給 user 用</li><li><a href>deep</a>：所有的歷史訊息，但是優先性比較低</li></ol><p>執行的 code 大概長的像以下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a6e22e>@task</span>()
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>job_task</span>(current_job)
</span></span><span style=display:flex><span>  <span style=color:#75715e># .process returns the next job to execute, or None if there are no more jobs to execute.</span>
</span></span><span style=display:flex><span>  next_job <span style=color:#f92672>=</span> current_job<span style=color:#f92672>.</span>process(router)
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> next_job:
</span></span><span style=display:flex><span>    job_task<span style=color:#f92672>.</span>delay(next_job, priority<span style=color:#f92672>=</span>LOW <span style=color:#66d9ef>if</span> next_job<span style=color:#f92672>.</span>deep <span style=color:#66d9ef>else</span> NORMAL)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>initial_job <span style=color:#f92672>=</span> HistoricalIndexJob(guild_id<span style=color:#f92672>=</span><span style=color:#ae81ff>112233445566778899</span>)
</span></span><span style=display:flex><span>job_task<span style=color:#f92672>.</span>delay(initial_job) 
</span></span></code></pre></div><h1 id=實際在-production-的過程><strong>實際在 Production 的過程</strong></h1><h2 id=初始化實驗><strong>初始化實驗</strong></h2><p>最精采的實戰部分來拉，我們根據以上的設計，一開始先開 single Elasticsearch cluster (只有 3 個 Nodes)，然後部屬 index workers，然後排程最大的 1000 個使用者的 servers 來 index，這個階段是做實驗，我們會仔細研究 metrics，我們注意到兩件事情：</p><ol><li><a href>CPU 使用比預期的高</a></li><li><a href>Disk 使用成長太快</a></li></ol><p>跑一段時間之後，Disk 快沒空間了，我們取消了 index 的過程，事情真的怪怪的……</p><p>結果第二天上班回來，<strong>我們發現神奇的事情 Disk 縮小了！！我們開始懷疑是不是 Elasticsearch 把我們的資料丟了，但是打一下 API 不僅正確而且超級快！為啥？？？？？？？</strong></p><h3 id=disk-成長量><strong>Disk 成長量</strong></h3><p><img src=/images/discord-fulltext_0.png alt></p><h3 id=cpu-使用率><strong>CPU 使用率</strong></h3><p><img src=/images/discord-fulltext_1.png alt></p><h2 id=研究的精神><strong>研究的精神</strong></h2><p>在研究了一下之後，我們提出一個 <strong>假說</strong>：<a href>預設情況 Elasticsearch 會以每 1 秒為單位，然後刷新 index，這可以提供 “near real-time” 搜尋的能力，而且同時會把數千個 index 放到 buffer 中 Lucene segment。晚上 Elasticsearch 就會偷偷合併 segment，所以 Disk 就會縮減容量。</a></p><p>要測試這個假說也很簡單，就直接把所有先前的 index 丟掉，然後把刷新的間隔調超大，CPU 瞬間歸零，Disk 也沒有爆炸性增長，太神拉！</p><h3 id=disk-成長量-調整刷新參數過後><strong>Disk 成長量 (調整刷新參數過後)</strong></h3><p><img src=/images/discord-fulltext_2.png alt></p><h3 id=cpu-使用率-調整刷新參數過後><strong>CPU 使用率 (調整刷新參數過後)</strong></h3><p><img src=/images/discord-fulltext_3.png alt></p><h2 id=更新的煩惱><strong>更新的煩惱</strong></h2><p>顯然，Elasticsearch 內建的 near real-time index 我們沒有要用。可能一個 server 好幾個小時都沒有一次查詢，我們必須在 Application Layer 設計一層更新策略。<a href>我們用 Redis Expiring hashmap 做到這點，由於本身 server 和 Elasticsearch 一起被 shard，我們可以很方便的持續追蹤更新狀態。</a></p><p>實踐上也很簡單，<a href>Redis key 就是 prefix + shard_key 的 Hashmap 管理 guild_id ⇒ sentinel value，由此決定要不要刷新 index</a>，以下是完整的 lifecycle：</p><h3 id=indexing-lifecycle><strong>Indexing lifecycle</strong></h3><ol><li><strong>從 Queue 取 N 則訊息</strong></li><li><strong>用 guild_id 找到需要 route 的 shard</strong></li><li><strong>執行 bulk insert</strong></li><li><strong>更新 Redis mappings 標記成 dirty，一個小時後就會過期</strong></li></ol><h3 id=search-lifecycle><strong>Search lifecycle</strong></h3><ol><li><strong>根據 guild_id 找到自己需要的搜尋的 shard</strong></li><li><strong>檢查 Redis mapping，是否要查的 guild_id 是 dirty</strong></li><li><strong>如果是 dirty 刷新 Elasticsearch Index，然後標記成 clean</strong></li><li><strong>執行 query 本身</strong></li></ol><p>你可能已經發現，<a href>我們設計流程已經有包含了刷新邏輯，不過我們還是有設計每個小時的自動刷新 index。也就是說就算 Redis 掛了，最多一個小時之後，系統就會自動修復。</a></p><h1 id=the-future><strong>The Future</strong></h1><p>目前為止，我們運行了 <a href>14 nodes, 2 clusters 用的機器是 n1-standard-8 instance (GCP)</a>，都帶有 <a href>1TB 的 SSD</a>。總共的 <a href>document 有 26 billion</a>。增加的速度大約<a href>每秒 30,000 messages，Elasticsearch 大約只花了 5–15% CPU。</a></p><p>我們的 library 可以讓我們輕鬆的增加 nodes 都不是問題，shard 真是偉大的發明阿！</p><p>至於甚麼時候要擴張我們的 cluster，我們參考四個主要指標：</p><ol><li><strong><a href>heap_free</a></strong>：JVM 如果發生了 <strong>Stop-The-World GC，那叫要考慮加 node 了</strong>。</li><li><strong><a href>disk_free</a></strong>：沒有 Disk 空間當然就要加 node，不過單純 Disk 不夠用 GCP 可以輕鬆的換機器大小，GCP 真香。</li><li><strong><a href>cpu_usage</a></strong>：CPU usage 在尖峰時刻過高</li><li><strong><a href>io_wait</a></strong>：如果 I/O 操作過於緩慢的話</li></ol><h2 id=exampleunhealthy-cluster-ran-out-of-heap>Example：Unhealthy Cluster (ran out of heap)</h2><h3 id=heap-free-mib><strong>Heap Free (MiB)</strong></h3><p><img src=/images/discord-fulltext_4.png alt></p><h3 id=time-spent-gcs><strong>Time Spent GC/s</strong></h3><p><img src=/images/discord-fulltext_5.png alt></p><h2 id=examplehealthy-cluster>Example：<strong><strong>Healthy Cluster</strong></strong></h2><h3 id=heap-free-gib><strong>Heap Free (GiB)</strong></h3><p><img src=/images/discord-fulltext_6.png alt></p><h3 id=time-spent-gcs-1><strong>Time Spent GC/s</strong></h3><p><img src=/images/discord-fulltext_77.png alt></p><h1 id=結論><strong>結論</strong></h1><p>截至目前為止，我們的系統都表現的超棒，身為使用者的我也這麼覺得 XD。<a href>Elasticsearch 從 0 到 26 billion documents 包含 16,000 indices，都沒有甚麼問題</a>。在未來或許我們會考慮寫在 clusters 之間 migrate indices，以防出現那種超級多訊息的 Discord server，不過作者說目前為止好像沒有必要拉 XD，我們的 sharding 做得很好。</p><h1 id=感想><strong>感想</strong></h1><p>這部分我就寫寫我自己的感想吧！在研究這篇文章時我原本預期會沒啥內容，阿不就 Elasticsearch 開下去就好了 XD 不過比我想的精彩許多，<a href>由於 Discord 已經是超大的 SaaS，完全信任第三方的 Infra 本身就蘊含了不確定性危機，用自己可以控制的 code 去使用第三方軟體開發服務是一個折衷的策略。</a></p><p>回到以前在和周志遠老師學分散是系統的時候，第一章說分散式系統是靠溝通達成的，這篇文章算是給我一個很大的實際案例解說，在文章裡面你沒有看到一堆超硬的 Algorithm，而是如何精妙的打造產品，用的工具也就是 Queue 和 Worker 而已，看完覺得感動 >///&lt;。</p></section><div class=post-tags></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/tachunwu rel=me title=GitHub><i data-feather=github></i></a>
<a class=border></a></div><div class=footer-info>2023 💠 © Tachunn | <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-2LYZQ778V0"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2LYZQ778V0")</script><script>feather.replace()</script></div></body></html>